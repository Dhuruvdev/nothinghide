Integrate an agentic, lightweight, explainable deepfake risk detection system into an existing web app, optimized for CPU-only environments (Replit).
The system must be fast, smooth, modular, and authentic, suitable for pre-beta public use.
ğŸ§  SYSTEM ROLE (VERY IMPORTANT)
You are a Senior AI Systems Architect + Backend Engineer building a pre-beta trust & authenticity engine.
You prioritize speed, explainability, safety, and modular upgrades, not raw benchmark accuracy.
ğŸ§© CORE REQUIREMENTS
1ï¸âƒ£ Architecture Style
Agentic architecture (multi-agent, decision-driven)
NO single monolithic model
Each agent must be independent, replaceable, and explainable
2ï¸âƒ£ Allowed Models & Libraries (Replit Safe)
MobileNetV3 (pre-trained, CPU)
MediaPipe (face detection + landmarks)
OpenCV
librosa (optional audio)
PyTorch (inference only)
FastAPI
âŒ No transformers
âŒ No heavy YOLO
âŒ No GPU assumptions
âŒ No training in runtime
ğŸ§  AGENT DEFINITIONS (MANDATORY)
ğŸ§  Orchestrator Agent
Decides which agents to execute
Skips unnecessary computation
Handles timeouts & fallbacks
Rules:
If input = image â†’ skip temporal & audio agents
If no face detected â†’ return â€œInsufficient dataâ€
If video > 30s â†’ sample frames (1 fps)
ğŸ‘ï¸ Visual Artifact Agent
Model: MobileNetV3 (pre-trained)
Detects:
Over-smoothed skin
Texture inconsistency
Blending artifacts
Output:
Copy code
Json
{
  "artifact_score": 0.0â€“1.0,
  "confidence": "low | medium | high"
}
ğŸ™‚ Face Integrity Agent
Model: MediaPipe
Detects:
Eye blink frequency
Landmark jitter
Head pose instability
Mouthâ€“eye sync anomalies
No ML training required.
â±ï¸ Temporal Logic Agent
(NO deep learning)
Detects:
Frame similarity spikes
Motion physics breaks
Interpolation artifacts
ğŸ”Š Audio Consistency Agent (Optional)
Uses librosa:
Pitch flatness
Silence irregularity
Audio-video desync
Auto-disable if:
No audio
System under load
ğŸ§© Evidence Aggregator Agent
Combines outputs from all agents
Uses rule-based reasoning, not averaging
Produces structured evidence
Example reasoning:
â€œVisual artifacts + unstable landmarks + normal audio â†’ likely face-swapâ€
ğŸ§® Risk Scoring Agent
Dynamic weighting based on input type
Example:
Copy code
Text
Video:
Visual 35%
Temporal 35%
Face 20%
Audio 10%

Image:
Visual 60%
Face 40%
Output:
Copy code
Json
{
  "authenticity_score": 0â€“100,
  "risk_level": "Low | Medium | High",
  "model_confidence": "Experimental (Pre-Beta)"
}
ğŸ—£ï¸ Explanation Agent (CRITICAL)
Must convert machine results into human-readable trust explanations.
Example output:
Copy code

Why flagged:
â€¢ Facial texture unusually smooth
â€¢ Eye blink frequency below natural range
â€¢ Motion transitions inconsistent
NO technical jargon in user output.
ğŸŒ API INTEGRATION (Existing Web App)
Endpoint
Copy code

POST /api/scan
Input
Image or video file
Max size: configurable
Async processing preferred
Output (JSON)
Copy code
Json
{
  "authenticity_score": 72,
  "risk_level": "Medium",
  "confidence": "Experimental",
  "explanation": [
    "Facial texture appears overly smooth",
    "Eye blink frequency lower than expected"
  ]
}
ğŸ–¥ï¸ UI REQUIREMENTS (Pre-Beta Safe)
Show score + reason, not â€œFake / Realâ€
Always display disclaimer:
â€œThis is an experimental AI pre-beta result. Do not use as legal proof.â€